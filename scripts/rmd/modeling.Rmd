---
title: Modeling
author: Daniel Anderson
output: 
  rmdformats::downcute:
    code_folding: hide
---

```{r include = FALSE}
library(tidyverse)
library(lme4)
theme_set(theme_minimal(15))

knitr::opts_chunk$set(
  message = FALSE,
  warning = FALSE,
  cache = TRUE
)
```

This doc is for sharing the modeling I've done so far. 

# Research Questions
1. To what extent do achievement disparities between students who are and are not classified as economically disadvantaged vary between schools?
2. To what extent do these achievement disparities change over time?
3. To what extent do absenteeism rates for students who are and are not classified as economically disadvantaged vary between schools?
4. Are observed achievement disparities, and trends in achievement disparities, moderated by absenteeism rates?
5. Do school-level absenteeism rates, and disproportionality in absenteeism rates between students who are and are not classified as economically disadvantaged, relate to the school-level (average) achievement disparity?


## Preliminary stuff

I wanted to start by exploring the trajectories over time a bit. I was particularly interested in the functional form. The below makes it pretty clear that a cubic fit is following the means at each time point near perfectly.

```{r}
d <- readr::read_csv(here::here("data", "analytic-sample.csv"))

#### Plots
d |>
  group_by(grade) |>
  summarize(score = mean(rit_tot, na.rm = TRUE)) |>
  ggplot(aes(grade, score)) +
  geom_smooth(
    method = "lm",
    color = "pink",
    se = FALSE
  ) +
  geom_smooth(
    method = "lm",
    color = "orange",
    formula = y ~ poly(x, 2),
    se = FALSE
  ) +
  geom_smooth(
    method = "lm",
    formula = y ~ poly(x, 3),
    se = FALSE
  ) +
  geom_point(size = 3)
```

So I expect to move forward with a cubic model. Let's see how this looks by group, however.

```{r}
d |>
  group_by(grade, econ_dis_stable) |>
  summarize(score = mean(rit_tot, na.rm = TRUE)) |>
  ggplot(aes(grade, score)) +
  geom_smooth(
    aes(color = factor(econ_dis_stable)),
    method = "lm",
    formula = y ~ poly(x, 3),
    se = FALSE
  ) +
  geom_point(
    aes(group = factor(econ_dis_stable)),
    size = 3
  )
```

# Modeling

## Unconditional growth model
Below I fit a linear model and a cubic model and compare the fit. The cubic model clearly fits better.

```{r}
m0 <- lmer(
  rit_tot ~ wave +
    (wave | ssid) + (wave | schid),
  data = d,
  control = lmerControl(optimizer = "bobyqa"),
  REML = FALSE
)

m01 <- lmer(
  rit_tot ~ poly(wave, 3) +
    (wave | ssid) + (wave | schid),
  data = d,
  control = lmerControl(optimizer = "bobyqa"),
  REML = FALSE
)

# polynomial model clearly fits better, unsurprisingly
anova(m0, m01)
```

## Economically-based achievement disparities
I first modeled the average disparity, then allowed that disparity to vary by grade. The model that allowed the disparity to vary between schools clearly fit the data better than the model that included only the mean difference, and both models clearly fit better than the unconditional growth model. 

### Average disparity
```{r}
# add economically disadvantaged
m1 <- lmer(
  rit_tot ~ poly(wave, 3) + econ_dis_stable +
    (wave | ssid) + (wave | schid),
  data = d,
  control = lmerControl(optimizer = "bobyqa"),
  REML = FALSE
)
anova(m01, m1) # clearly better
summary(m1)
```

### RQ 1
```{r}
# Model between-school variance in the average disparity
m2 <- lmer(
  rit_tot ~ poly(wave, 3) + econ_dis_stable +
    (wave | ssid) + (wave + econ_dis_stable | schid),
  data = d,
  control = lmerControl(optimizer = "bobyqa"),
  REML = FALSE
)
anova(m1, m2)
summary(m2)
```

This model can be used to address RQ1. We might say something like:

> Students classified by the Oregon Department of Education as "economically disadvantaged" scored approximately 56 points lower on the statewide assessment than their peers who were not classified. This represents approximately 0.70 standard deviations on the mathematics statewide test in Grade 3, and 0.47 standard deviations on the Grade 7 statewide test. This mean difference, however, varied considerably between schools with a standard deviation of 14.47. In other words, the achievement disparity in a school one standard deviation above the mean would be 70 points different, while a school one standard deviation below the mean would be approximately 42 points (the difference between the achievement of these students being roughly half a standard deviation below their peers as opposed to 0.89 standard deviations below, at Grade 3). This was consistent with our hypothesis.


Below the effect-size like metrics I reference from above.

```{r}
d |>
  group_by(grade) |>
  summarize(sd = sd(rit_tot, na.rm = TRUE)) |>
  mutate(
    es = abs(fixef(m2)["econ_dis_stable"]) / sd,
    above = (abs(fixef(m2)["econ_dis_stable"]) + 14.47) / sd,
    below = (abs(fixef(m2)["econ_dis_stable"]) - 14.47) / sd,
  )
```

### RQ 2
To address the second research question - how do these disparities change over time - we model the interaction between economically disadvantaged status and wave.

```{r}
m3 <- lmer(
  rit_tot ~ poly(wave, 3) + econ_dis_stable + econ_dis_stable:wave +
    (wave | ssid) + (wave + econ_dis_stable | schid),
  data = d,
  control = lmerControl(optimizer = "nlminbwrap"),
  REML = FALSE
)
anova(m2, m3)
```

We see again that the model including this interaction clearly fits better. However, I was also interested to if the curvillinear parts depended on group membership.

```{r}
m3b <- lmer(
  rit_tot ~ poly(wave, 3) * econ_dis_stable + 
    (wave | ssid) + (wave + econ_dis_stable | schid),
  data = d,
  control = lmerControl(optimizer = "nlminbwrap"),
  REML = FALSE
)
anova(m3, m3b)
```

The model including the interaction on the curvillinear pieces fits better, so we'll go forward with that. 

```{r}
summary(m3b)
```

We also see that the disparity grows over time, but because of the non-linearity it's sort of difficult to interpret directly. We can use this to address RQ2, however, and we might say something like

> Students classified as economically disadvantaged gained progressed at a slower rate than student who were not similarly classified. Figure 1 displays the average growth (not accounting for any between-school variation) for each student group. As can be seen, the disparity grows over time. At Grade 3, the predicted difference between these groups was approximately 52.25 points, which grew to 75.77 points by Grade 7. However, the variation in scores also increased with time, and these values represent roughly equivalent effect sizes for the corresponding grade (0.66 standard deviations in Grade 3 and 0.63 standard deviations in Grade 7). 

I can make the plot prettier, of course, but a start of a draft is below.
```{r}
pred_frame <- expand.grid(
  wave = 0:4,
  econ_dis_stable = 0:1,
  ssid = -999,
  schid = -999
)
pred_frame$pred <- predict(
  m3b,
  newdata = pred_frame,
  allow.new.levels = TRUE
)

pred_frame |>
  pivot_wider(names_from = "econ_dis_stable", values_from = "pred") |>
  mutate(`0` - `1`)


means <- d |>
  group_by(grade, econ_dis_stable) |>
  summarize(
    score = mean(rit_tot, na.rm = TRUE),
    se = sundry::se(rit_tot),
    lower = score + qnorm(0.025) * se,
    upper = score + qnorm(0.975) * se
  )

ggplot(means, aes(grade, score)) +
  geom_line(
    aes(x = wave + 3, y = pred, color = factor(econ_dis_stable)), 
    pred_frame,
    size = 2
  ) +
  geom_errorbar(
    aes(ymin = lower, ymax = upper),
    width = 0.2,
    color = "gray50"
  ) +
  geom_point(
    aes(group = factor(econ_dis_stable)),
    size = 3,
  ) +
  scale_color_manual(
    "Economic Disadvantaged Status",
    values = c("#79a6e9", "#333E5C")
  ) +
  theme(legend.position = "bottom")
```

## Absenteeism

When adding absenteeism to the model, I followed a similar process as with economic disadvantaged status. This included first adding it as a main effect, then allowing it to vary randomly between schools, then investigating interactions. However, as I mentioned in our meeting on 01/20/2022, Oregon has fairly considerable variation in the number of days schools are open across districts. I therefore started by including this variable (number of days in the school year) as a (standardized) control variable.

```{r}
m4 <- lmer(
  rit_tot ~ poly(wave, 3) * econ_dis_stable + sy_days_z +
    (wave | ssid) + (wave + econ_dis_stable | schid),
  data = d,
  control = lmerControl(optimizer = "nlminbwrap"),
  REML = FALSE
)
anova(m4, m3b)
```

The fit of the model is essentially equivalent. We could opt for parsimony here but I'll keep it in there becuase I think it's an important control variable for the next step, which is adding in the number of days absent.

In my preliminary modeling, I tried to do what I discussed in the pre-registration, which is standardize it so it has a mean of zero and a standard devaition of 1, but the one standard deviation increase would represent a 5 day increase in days abent (one week). This ended up not working. I got warnings from lme4 about predictors being on very different scales. So I just ended up going with a standard scaling, and we can convert it back to the raw scale to make sense of it, as I'll illustrate below.

```{r}
m5 <- lmer(
  rit_tot ~ poly(wave, 3) * econ_dis_stable +
    sy_days_z + days_absent_z +
    (wave | ssid) + (wave + econ_dis_stable | schid),
  data = d,
  control = lmerControl(optimizer = "nlminbwrap"),
  REML = FALSE
)
anova(m4, m5)
```

And as we would expect, this model actually does fit better.
```{r}

```